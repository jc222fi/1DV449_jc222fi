### Inledning
När det var dags för att göra en mashup och få med alla kunskaper vi har lärt oss under kursen hade jag lite brist på idéer, men efter mångt och mycket landade jag på att sammanställa poster från Twitter och Flickr som har samma hastag. Det finns en liknande tjänst som heter Keyhole, men den inkluderar även Facebook, och inte bara hashtags utan även URLer, samt att den visar mer information än bara vilka poster och inlägg det är. Min applikation är mer tänkt som ett tidsfördriv, men man kan även se det som ett slags marknadsundersökning. Mycket annonsering sker i dagsläget i sociala medier eftersom användandet av dem är så utbrett och potentiella kunder är uppkopplade där flera gånger dagligen om inte kontinuerligt.
Efter att ha gjort klart det mesta av grundfunktionaliteten mot Twitter och Flickr kändes den dock lite tunn och tråkig, så jag lade till en lite mer komisk funktion som man kan använda efter att en sökning har gjorts. Om det finns ansikten i bilderna kan man trycka på piratknappen för att få fram en pirathatt och en ögonlapp som positionerar sig i proportion till ansiktet som upptäckts i bilderna.

### Schematisk bild över Twickrtags
* [Schemat hittar du här](https://drive.google.com/file/d/0B_ZzfQFknpytbEYzSXE5U1ljekU/view?usp=sharing)

### Säkerhet och prestandaoptimering
Twickrtags är en applikation som är ganska krävande vid första sökningen på en hashtag som ingen sökt på tidigare. För att göra det möjligt att lägga till piratdetaljerna måste API:et som används för ansiktsidentifiering anropas för varje bild som används från Flickr, och det är det inte riktigt anpassat för. Därför försöker jag cachea så mycket resurser som möjligt så länge som möjligt, och eftersom jag har märkt att innehållet från Flickr inte ändras så ofta har jag valt att spara det svaret från Flickr så länge som möjligt. Eftersom bilderna är kopplade till ansiktsidentifieringen sparar jag dessa två resurser lika länge, 1 timme för att vara exakt. Tweets från Twitter är mycket mer föränderliga, dessa resurser sparas endast i 15 minuter. Det är inte avgörande för applikationens funktionalitet att tweetsen är färskare än så.
För att vinna så mycket som jag kan på optimeringsfronten har jag även valt att minifiera min JavaScriptfil, resursvinsten blir inte så stor men det gäller att göra vad man kan för optimeringen när man är medveten om att vissa delar av applikationen är tunga eller har lång laddtid. Den tyngsta laddtiden har Keylemons API som jag använder för att hitta ansikten i bilderna, och det är också den svaga länken i min applikation eftersom deras gräns för anrop är ganska låg per timme när man har registrerat sig för en gratis API-nyckel. Det räcker med några stycken tidigare ej gjorda sökningar för att de tillåtna anropen per timme ska vara fullt utnyttjade, och då fungerar inte längre piratknappen för sökord som ej gjorts tidigare. Detta kan också vara ett problem om man gör en ny sökning som faktiskt innehåller ansikten, dessas sparas då i cachen som ansiktslösa bilder i en timme. Dessvärre har jag även upptäckt en bugg i den wrapper som jag använder för att cachea data, den raderar inte poster även om de är utgångna.

### Offline-first
Min applikation är svår att få till i ett offline läge eftersom stora delar av den är beroende av data som produceras och hämtas live. Jag ha räven valt att skriva min applikation i php eftersom jag känner mig rätt bekväm med det språket, men det gör det lite knivigare att implementera offline-first eftersom det alltid körs på serversidan. Jag hade en tanke att implementera en liten sqlite internt i applikationen där det senaste sökresultatet alltid sparas och hämtas, men den skulle då inte fungera optimalt med själva sökfunktionen utan enbart presentera tidigare sökresultat. Dessvärre rann tiden ut för mig, men denna implementation är fortfarande med i planeringen eftersom jag tycker om den applikation jag har skrivit och är sugen på att vidareutveckla och förbättra den även efter kursens slut. Jag gjorde ett försök att hämta data som finns sparat i cachen och presentera för användaren till en början, men dessvärre hann jag inte få till det så att det fungerar och det räknas förmodligen inte riktigt som offline-first eftersom det i php ändå måste till servern och vända för att presentera detta för användaren.

### Risker
Då jag valt att bara hämta publik data enligt tillhandahållna API:er från respektive informationskälla finns ingen direkt risk, man kan inte logga in på varken Twitter eller Flickr för att göra statusuppdateringar eller gilla något inlägg. För detta krävs ytterligare komplexitet i anropet eftersom man som användare då måste autentisera sig med sitt konto. Det är en ren presentationsapplikation där jag söker bland publikt innehåll för publika användare, dessa har valt att ha sina profiler och dess innehålla publika för alla att beskåda. Därmed visas ingen information som var menad som privat, men under utvecklingens gång och under testningen har jag märkt att vissa profiler på twitter som är publika borde inte vara det. Det finns profiler med pornografiskt riktat innehåll, och det hade varit önskvärt att twitters API hade någon parameter för exempelvis ”parental control” eller liknande. Dessa inlägg kan taggas med till synes oskyldiga hashtags såsom ”happy”, och helt plötsligt kan användaren få se saker som inte var tanken från början och som kan uppfattas som stötande.
Texten som skickas med formuläret till servern valideras för att ta bort specialtecken och göra allting till små bokstäver innan det skickas vidare till respektive API, detta för att texten måste se ut på ett visst sätt innan förfrågan skickas men även för att man inte ska kunna skriva in taggar och annat innehåll för att göra skada någonstans.

### Egen reflektion
Jag var till viss del rätt otaggad på den här uppgiften, mest för att jag inte kom på något att göra som jag brann för. Jag trodde till en början att resultatet skulle bli mer komiskt när resultaten från Twitter parades ihop med bilder från Flickr, men fantasin överträffade dessvärre verkligheten den här gången. De flesta resultaten blev antingen ganska intetsägande och passade ihop, medan andra blev totalt nonsens. Den stora räddningen kom när jag kom på min piratknapp, vissa resultat av den funktionen är utomordentligt bra och roliga, medan andra är lite mindre bra och roliga. Jag är mest nöjd med att jag fick till positioneringen av piratdetaljerna så pass bra som det blev, satt länge och funderade på hur jag skulle kunna få med mig koordinaterna man får i svaret från Keylemon som jag använder för ansiktsidentifieringen till min JavaScriptfil där jag behandlar alla händelser som piratknappen triggar igång. Den stora utmaningen var att man kunde göra anrop och skicka med en lista med URLer till bilder man ville se om de innehöll några ansikten. Detta var det snabbaste alternativet eftersom det bara handlade om ett anrop, men dessvärre kunde inte ansiktena som returnerades kopplas till URLerna som skickades med anropet på ett tillfredsställande sätt, och jag var då tvungen att göra avkall på prestandan och skicka ett anrop per URL med foto. Just den här delen av implementationen är jag inte speciellt nöjd med, men efter mycket rådbråkande med mig själv har jag inte kommit på något annat sätt att göra det på än så länge. Detta är något jag planerar att fundera vidare på och försöka förbättra eftersom det är en så stor del av det häftiga med min applikation.
Det finns en hel del att göra på prestandan och optimeringen, men det är något som kommer att förbättras i framtiden. Vidareutveckling av applikationen kommer främst att koncentreras på att förbättra sättet jag hanterar Keylemons API för ansiktidentifiering och min implementation av cachening. Det finns i dagsläget en del buggar i dessa två implementationer, exempelvis fungerar inte mina villkor för hanteringen av svaret från Keylemon när det är null, och cachead data raderas inte fastän dess utgångsdatum har passerat. Gällande cacheat data är detta förmodligen en bugg i det bibliotek jag använder för den implementationen, men jag hann dessvärre inte hitta något alternativ att implementera i tid till deadline. Min implementation av Keylemon lämnar en del övrigt att önska, och detta är något som jag kommer behöva fundera en hel del på över hur jag kan förbättra den och på så vis öka prestandan, och givetvis korrigera felhanteringen av null-värden. Jag har även tänkt kika runt om det kan finnas något alternativ till Keylemon som har ett svar som är bättre utformat för att passa mina ändamål.
